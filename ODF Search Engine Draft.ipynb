{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jtorr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------------------------\n",
    "#\n",
    "#  Moteur de recherche et de recommendation - Open Food Data\n",
    "#\n",
    "#-------------------------------------------------------------------------------------------\n",
    "#\n",
    "# Importing the libraries\n",
    "#\n",
    "#-------------------------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import Image, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "#    from wordcloud import WordCloud, STOPWORDS  - needs Python 3.7\n",
    "#\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------------------------\n",
    "#\n",
    "#  Fonction clean_chars qui remplace des characters dans un dataframe par un autre\n",
    "#  utilisée pour remplacer des lettres avec des signes diacritiques\n",
    "#\n",
    "#  strng1: string contenant les characters à remplacer\n",
    "#  strng2: string contenant les characters à chercher\n",
    "#  strng3: string contenant les characters remplaçants\n",
    "#\n",
    "#  CHANGE DANS STRNG1 TOUS LES CHARACTERS DANS STRING2 PAR LE(s) CHARACTER(S) DANS STRING3\n",
    "#\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "\n",
    "def clean_chars(strng1, strng2, strng3):\n",
    "    for c in strng2:\n",
    "        if (c in strng1):\n",
    "            strng1 = strng1.replace(c,strng3)\n",
    "    return strng1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123145, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------------------------\n",
    "#\n",
    "# Importing the dataset\n",
    "#\n",
    "#-------------------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------------\n",
    "# \n",
    "# Chargement du fichier fr.openfoodfacts.products.csv\n",
    "# Le fichier est placé dans le repertoire courant. \n",
    "# Le fichier contient uniquement des produits vendus en France\n",
    "#\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "food_data = pd.read_csv('fr.openfoodfacts.products.csv', sep=',',\n",
    "                        usecols=['code',\n",
    "                                 'product_name',\n",
    "                                 'brands',\n",
    "                                 'categories',\n",
    "                                 'ingredients_text',\n",
    "                                 'allergens',\n",
    "                                 'traces',\n",
    "                                 'nutrition_grade_fr',\n",
    "                                 'energy_100g',\n",
    "                                 'sugars_100g',\n",
    "                                 'fiber_100g',\n",
    "                                 'proteins_100g',\n",
    "                                 'sodium_100g',\n",
    "                                 'alcohol_100g',\n",
    "                                 'fruits-vegetables-nuts_100g',\n",
    "                                 'nutrition-score-fr_100g'\n",
    "                                ],\n",
    "                        dtype = {'code': str,\n",
    "                                 'product_name': str,\n",
    "                                 'brands': str,\n",
    "                                 'categories': str, \n",
    "                                 'ingredients_text': str,\n",
    "                                 'allergens': str,\n",
    "                                 'traces': str,\n",
    "                                 'nutrition_grade_fr': str,\n",
    "                                 'energy_100g': float,\n",
    "                                 'sugars_100g': float,\n",
    "                                 'fiber_100g': float,\n",
    "                                 'proteins_100g': float,\n",
    "                                 'sodium_100g': float,\n",
    "                                 'alcohol_100g': float,\n",
    "                                 'fruits-vegetables-nuts_100g': float, \n",
    "                                 'nutrition-score-fr_100g': float\n",
    "                                }\n",
    "                       )\n",
    "#\n",
    "food_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                   Farine de blé noir\n",
      "1                  Naturablue original\n",
      "2                        Filet de bœuf\n",
      "3                 Naturakrill original\n",
      "4                       Lion Peanut x2\n",
      "5                              Twix x2\n",
      "6                       Pack de 2 Twix\n",
      "7                     lentilles vertes\n",
      "8                            Root Beer\n",
      "9    Biscuits sablés fourrage au cacao\n",
      "Name: product_name, dtype: object \n",
      "\n",
      "0     Ferme t'y R'nao\n",
      "1         Natura4ever\n",
      "2                 NaN\n",
      "3         Natura4ever\n",
      "4                 NaN\n",
      "5                 NaN\n",
      "6      Twix, Lundberg\n",
      "7    Bertrand Lejeune\n",
      "8                 A&W\n",
      "9           St Michel\n",
      "Name: brands, dtype: object \n",
      "\n",
      "0                                                  NaN\n",
      "1                                                  NaN\n",
      "2                                        Filet de bœuf\n",
      "3                                                  NaN\n",
      "4                                                  NaN\n",
      "5                                                  NaN\n",
      "6                                                  NaN\n",
      "7    Aliments et boissons à base de végétaux,Alimen...\n",
      "8    Boissons,Boissons gazeuses,Sodas,Boissons sucr...\n",
      "9    Snacks sucrés,Biscuits et gâteaux,Biscuits,Sablés\n",
      "Name: categories, dtype: object \n",
      "\n",
      "0                                                  NaN\n",
      "1                                                  NaN\n",
      "2                                                  NaN\n",
      "3                                                  NaN\n",
      "4                                                  NaN\n",
      "5                                                  NaN\n",
      "6                                                  NaN\n",
      "7                                     lentilles vertes\n",
      "8    Eau gazéifiée, sirop de maïs à haute teneur en...\n",
      "9    Sucre, farine de _Blé_, graisse et huiles végé...\n",
      "Name: ingredients_text, dtype: object \n",
      "\n",
      "0                             NaN\n",
      "1                             NaN\n",
      "2                             NaN\n",
      "3                             NaN\n",
      "4                             NaN\n",
      "5                             NaN\n",
      "6                             NaN\n",
      "7                             NaN\n",
      "8                             NaN\n",
      "9    Blé, Beurre, Oeufs, Noisette\n",
      "Name: allergens, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------------------------\n",
    "#\n",
    "#  Exploring the alphabetic fields the dataset. \n",
    "#\n",
    "#  code\n",
    "#  product_name\n",
    "#  brands\n",
    "#  categories\n",
    "#  ingredients_text\n",
    "#  allergens\n",
    "#  traces\n",
    "#\n",
    "#-------------------------------------------------------------------------------------------\n",
    "\n",
    "col_names = ['product_name','brands','categories','ingredients_text','allergens']\n",
    "\n",
    "for col in col_names:\n",
    "    print(food_data[col].head(n=10),'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code                                0\n",
       "product_name                        2\n",
       "brands                           6343\n",
       "categories                      46635\n",
       "ingredients_text                36383\n",
       "allergens                       92414\n",
       "traces                         100626\n",
       "nutrition_grade_fr              30118\n",
       "energy_100g                     26703\n",
       "sugars_100g                         0\n",
       "fiber_100g                          0\n",
       "proteins_100g                       0\n",
       "sodium_100g                     28512\n",
       "alcohol_100g                   120391\n",
       "fruits-vegetables-nuts_100g    120002\n",
       "nutrition-score-fr_100g         30118\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------------------------\n",
    "#\n",
    "#  Compter les nulls par colonne \n",
    "#\n",
    "#-------------------------------------------------------------------------------------------\n",
    "\n",
    "food_data.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123143, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------------------------\n",
    "#\n",
    "#  J'élimine les produits avec product_name null\n",
    "#\n",
    "#-------------------------------------------------------------------------------------------\n",
    "\n",
    "food_data = food_data.dropna(subset=['product_name'])\n",
    "\n",
    "food_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code                                0\n",
       "product_name                        0\n",
       "brands                           6342\n",
       "categories                      46633\n",
       "ingredients_text                36381\n",
       "allergens                       92412\n",
       "traces                         100624\n",
       "nutrition_grade_fr              30116\n",
       "energy_100g                     26701\n",
       "sugars_100g                         0\n",
       "fiber_100g                          0\n",
       "proteins_100g                       0\n",
       "sodium_100g                     28510\n",
       "alcohol_100g                   120389\n",
       "fruits-vegetables-nuts_100g    120000\n",
       "nutrition-score-fr_100g         30116\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_data.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------\n",
    "#\n",
    "#  Nettoyage de champs alphanmériques #1\n",
    "#\n",
    "#\n",
    "#  Remplacemente des nulls par des blancs\n",
    "#\n",
    "#-------------------------------------------------------------------------------------------\n",
    "\n",
    "col_names = ['brands','categories','ingredients_text','allergens','traces','nutrition_grade_fr']\n",
    "\n",
    "for col in col_names:\n",
    "    food_data[col] = food_data[col].fillna('') \n",
    "\n",
    "for col in col_names:\n",
    "    food_data[col] = food_data[col].str.strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                          \n",
      "1                                                          \n",
      "2                                             Filet de bœuf\n",
      "3                                                          \n",
      "4                                                          \n",
      "                                ...                        \n",
      "123140                                           thés verts\n",
      "123141                                                     \n",
      "123142    Viandes,Produits à tartiner,Charcuteries,Produ...\n",
      "123143                                                     \n",
      "123144                                                     \n",
      "Name: categories, Length: 123143, dtype: object\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code                                0\n",
       "product_name                        0\n",
       "brands                              0\n",
       "categories                          0\n",
       "ingredients_text                    0\n",
       "allergens                           0\n",
       "traces                              0\n",
       "nutrition_grade_fr                  0\n",
       "energy_100g                     26701\n",
       "sugars_100g                         0\n",
       "fiber_100g                          0\n",
       "proteins_100g                       0\n",
       "sodium_100g                     28510\n",
       "alcohol_100g                   120389\n",
       "fruits-vegetables-nuts_100g    120000\n",
       "nutrition-score-fr_100g         30116\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_data.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123143, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------------------------\n",
    "#\n",
    "#  Nettoyage de champs alphanumériques #2\n",
    "#\n",
    "#  Pour la suite, on va créer un nouveau dataframe \"corpus\", contenant le 'code' \n",
    "#  de produit dans une colonne et une autre contenant, et une concatenation de \n",
    "#  tous les champs alphabétiques sauf le nutritionscore_grade.\n",
    "#\n",
    "#  Sur ce nouveau dataframe, on va procéder au nettoyage des charactères spéciaux, \n",
    "#  de signes diacritiques, des signes orthographiques, etc., avec un '-' de separation.\n",
    "#\n",
    "#  Ce sera la dataframe pour le moteur de recherche du système de recommendation.\n",
    "#\n",
    "#-------------------------------------------------------------------------------------------\n",
    "\n",
    "col_names = ['code', 'description', 'description_bow']\n",
    "\n",
    "corpus = pd.DataFrame(columns = col_names)\n",
    "\n",
    "col_names = ['brands', 'categories', 'ingredients_text', 'allergens', 'traces']\n",
    "\n",
    "corpus['code'] = food_data['code']\n",
    "\n",
    "corpus['description'] = food_data[col_names].agg('-'.join, axis=1)\n",
    "\n",
    "corpus.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0000000003087\n",
      "1     0000000020114\n",
      "2     0000000024600\n",
      "3     0000000030113\n",
      "4     0000000036252\n",
      "5     0000000039259\n",
      "6     0000000039529\n",
      "7     0000005200016\n",
      "8     0000007020254\n",
      "9     0000007730009\n",
      "10    0000009336247\n",
      "11    0000010068175\n",
      "12    0000010090206\n",
      "13    0000010127735\n",
      "14    0000010179413\n",
      "15    0000010187319\n",
      "16    0000010207260\n",
      "17    0000020004552\n",
      "18    0000030053014\n",
      "19    0000040144078\n",
      "Name: code, dtype: object \n",
      "\n",
      "0                                   Ferme t'y R'nao----\n",
      "1                                       Natura4ever----\n",
      "2                                     -Filet de bœuf---\n",
      "3                                       Natura4ever----\n",
      "4                                                  ----\n",
      "5                                                  ----\n",
      "6                                    Twix, Lundberg----\n",
      "7     Bertrand Lejeune-Aliments et boissons à base d...\n",
      "8     A&W-Boissons,Boissons gazeuses,Sodas,Boissons ...\n",
      "9     St Michel-Snacks sucrés,Biscuits et gâteaux,Bi...\n",
      "10       Nerds-Snacks sucrés,Confiseries,Bonbons---Œufs\n",
      "11    Alice Délice-en:beverages-Thé noir aromatisé à...\n",
      "12    Alice Délice-Aliments et boissons à base de vé...\n",
      "13    Alice Délice-Sirops,Sirops pour ganache-Sirop ...\n",
      "14    Alice Délice--farine de blé (gluten), sucre de...\n",
      "15                                     Alice Délice----\n",
      "16                                     Alice Délice----\n",
      "17    Union des Vignerons des Cotes du Rhône-Boisson...\n",
      "18                                                 ----\n",
      "19                                            M&m's----\n",
      "Name: description, dtype: object \n",
      "\n",
      "0     NaN\n",
      "1     NaN\n",
      "2     NaN\n",
      "3     NaN\n",
      "4     NaN\n",
      "5     NaN\n",
      "6     NaN\n",
      "7     NaN\n",
      "8     NaN\n",
      "9     NaN\n",
      "10    NaN\n",
      "11    NaN\n",
      "12    NaN\n",
      "13    NaN\n",
      "14    NaN\n",
      "15    NaN\n",
      "16    NaN\n",
      "17    NaN\n",
      "18    NaN\n",
      "19    NaN\n",
      "Name: description_bow, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "col_names = ['code','description', 'description_bow']\n",
    "\n",
    "for col in col_names:\n",
    "    print(corpus[col].head(n=20),'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------------------------\n",
    "#\n",
    "#  Nettoyage de champs alphanmériques #2\n",
    "#\n",
    "#\n",
    "#  Remplacement des charactères spéciaux par des espaces blancs\n",
    "#\n",
    "#-------------------------------------------------------------------------------------------\n",
    "\n",
    "sp_ch = ['º','$', '%', '&','(',')','=','*','?','^','+','*','¨',';',':','`','-','_','/','´',\n",
    "         '_',',','ª','¿','¡','Ç','{','}','[',']','<','>','\\'','´']\n",
    "\n",
    "for sc in sp_ch:\n",
    "    corpus['description'] = corpus['description'].str.replace(sc,' ')\n",
    "\n",
    "print('Ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------------------------\n",
    "#\n",
    "#  Nettoyage de champs alphanmériques #3\n",
    "#\n",
    "#\n",
    "#  Remplacement des charactères avec des signes diacritiques par des charactères simplifiés\n",
    "# \n",
    "#  Le fichier alphabet.csv contient tous les lettres de l'alphabet avec toutes les\n",
    "#\n",
    "#  possibilités de signes diacritiques et son remplacement correspondant dans chaque cas\n",
    "#\n",
    "#-------------------------------------------------------------------------------------------\n",
    "#\n",
    "#  alphabet.csv contient deux colonnes de characters\n",
    "#\n",
    "#-------------------------------------------------------------------------------------------\n",
    "\n",
    "alphabet = pd.DataFrame(['initial','final'])\n",
    "\n",
    "alphabet = pd.read_csv('alphabet.csv',\n",
    "                     sep=',',\n",
    "                     usecols=['initial', 'final'],\n",
    "                     dtype = {'initial': str, 'final': str}\n",
    "                    )\n",
    "\n",
    "#-------------------------------------------------------------------------------------------\n",
    "#\n",
    "#  Remplacemet de tous les characters avec des signes diacritiques, lettres doubles, etc.\n",
    "#\n",
    "#-------------------------------------------------------------------------------------------\n",
    "\n",
    "for k in range(0,len(corpus)):\n",
    "    strng1 = corpus.iloc[k,1]\n",
    "    for i in range(0,len(alphabet)):\n",
    "        strng2 = alphabet.iloc[i,0]\n",
    "        strng3 = alphabet.iloc[i,1]\n",
    "        strng1 = clean_chars(strng1, strng2, strng3)\n",
    "    corpus.iloc[k,1] = strng1\n",
    "    \n",
    "print('Ready')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                   ferme t y r nao    \n",
      "1                                       natura4ever    \n",
      "2                                     filet de boeuf   \n",
      "3                                       natura4ever    \n",
      "4                                                      \n",
      "5                                                      \n",
      "6                                    twix  lundberg    \n",
      "7     bertrand lejeune aliments et boissons a base d...\n",
      "8     a w boissons boissons gazeuses sodas boissons ...\n",
      "9     st michel snacks sucres biscuits et gateaux bi...\n",
      "10      nerds snacks sucres confiseries bonbons   Oeufs\n",
      "11    alice delice en beverages the noir aromatise a...\n",
      "12    alice delice aliments et boissons a base de ve...\n",
      "13    alice delice sirops sirops pour ganache sirop ...\n",
      "14    alice delice  farine de ble  gluten   sucre de...\n",
      "15                                     alice delice    \n",
      "16                                     alice delice    \n",
      "17    union des vignerons des cotes du rhone boisson...\n",
      "18                                                     \n",
      "19                                            m m s    \n",
      "20    pepsi sodas au cola eau gazeifiee  sucre  colo...\n",
      "21    coca cola en beverages eau azeifiee   sucre   ...\n",
      "22                                                     \n",
      "23    bo frost  garniture sauce bechamel 60   eau  j...\n",
      "24                                         bo frost    \n",
      "25    marmite  40 ivlarmite original   extrait de le...\n",
      "26    7up pepsico sodas au citron boissons sucrees e...\n",
      "27    bijou snacks sucres desserts biscuits et gatea...\n",
      "28                                                     \n",
      "29    bijou cakes aux raisins cakes gateaux farine d...\n",
      "Name: description, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(corpus['description'].head(n=30),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0, len(corpus)):\n",
    "    corpus.iloc[i,1] = corpus.iloc[i,1].strip()\n",
    "    corpus.iloc[i,2] = corpus.iloc[i,1].split(' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          15\n",
       "1          11\n",
       "2          14\n",
       "3          11\n",
       "4           0\n",
       "         ... \n",
       "123140    106\n",
       "123141      0\n",
       "123142    238\n",
       "123143     12\n",
       "123144      5\n",
       "Name: description, Length: 123143, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "corpus['description'].map(len)\n",
    "\n",
    "# Fin de 8 mayo 2020 . continuaré el 9 de mayo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['code', 'tf_idf', 'cos_sim'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------------------------\n",
    "#   Dataframe qui contiendra tous les possibles réponses à la questions del utilisateur\n",
    "#-------------------------------------------------------------------------------------------\n",
    "\n",
    "col_names = ['code', 'tf_idf', 'cos_sim']\n",
    "\n",
    "corpus_vector = pd.DataFrame(columns = col_names)\n",
    "\n",
    "corpus_vector.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "farine de ble americain ou etrangere      \n",
      "['farine', 'de', 'ble', 'americain', 'ou', 'etrangere']\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------------------------\n",
    "#\n",
    "#  L'utilisateur introduit sa requête. Elle sera stockée dans la variable \"user_input\"\n",
    "#\n",
    "#-------------------------------------------------------------------------------------------\n",
    "\n",
    "user_input = \"farine de blé française où étrangère & % $\"\n",
    "\n",
    "#-------------------------------------------------------------------------------------------\n",
    "#\n",
    "#  user_input est nettoyé et normalisé tel que la description du corpus\n",
    "#\n",
    "#-------------------------------------------------------------------------------------------\n",
    "\n",
    "sp_ch = ['º','$', '%', '&','(',')','=','*','?','^','+','*','¨',';',':','`','-','_','/','´',\n",
    "         '_',',','ª','¿','¡','Ç','{','}','[',']','<','>','\\'','´']\n",
    "\n",
    "for sc in sp_ch:\n",
    "    user_input = user_input.replace(sc,' ')\n",
    "\n",
    "for i in range(0,len(alphabet)):\n",
    "    strng2 = alphabet.iloc[i,0]\n",
    "    strng3 = alphabet.iloc[i,1]\n",
    "    user_input = clean_chars(user_input, strng2, strng3)\n",
    "\n",
    "print(user_input)\n",
    "\n",
    "#\n",
    "# Les espaces blanc sont eliminés au début et à la fin\n",
    "#\n",
    "\n",
    "user_input = user_input.strip()\n",
    "\n",
    "#\n",
    "# user_input est transformé en \"sac de paroles (bag of words)\"\n",
    "#\n",
    "user_input_BoW = user_input.split(' ')\n",
    "\n",
    "print(user_input_BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------------\n",
    "#\n",
    "# Initialize CountVectorizer\n",
    "#\n",
    "# In order to start using TfidfTransformer you will first have to create a CountVectorizer \n",
    "# to count the number of words (term frequency), limit your vocabulary size, \n",
    "# apply stop words and etc. The code below does just that.\n",
    "#\n",
    "#-------------------------------------------------------------------------------------------\n",
    "#   instantiate CountVectorizer()\n",
    "#-------------------------------------------------------------------------------------------\n",
    "\n",
    "cv = CountVectorizer()\n",
    " \n",
    "# this steps generates word counts for the words user_input\n",
    "word_count_vector=cv.fit_transform(corpus['description'])\n",
    "\n",
    "word_count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "iterrows not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-92be73bceb2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword_count_vector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    689\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 691\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" not found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: iterrows not found"
     ]
    }
   ],
   "source": [
    "word_count_vector.iterrows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
